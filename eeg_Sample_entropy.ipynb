{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "from decimal import Decimal\n",
    "from PIL import Image\n",
    "import mne\n",
    "import pandas as pd\n",
    "##code from https://github.com/nikdon/pyEntropy/blob/master/pyentrp/entropy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_entropy(time_series, sample_length, tolerance = None):\n",
    "    \"\"\"Calculates the sample entropy of degree m of a time_series.\n",
    "    This method uses chebychev norm.\n",
    "    It is quite fast for random data, but can be slower is there is\n",
    "    structure in the input time series.\n",
    "    Args:\n",
    "        time_series: numpy array of time series\n",
    "        sample_length: length of longest template vector\n",
    "        tolerance: tolerance (defaults to 0.1 * std(time_series)))\n",
    "    Returns:\n",
    "        Array of sample entropies:\n",
    "            SE[k] is ratio \"#templates of length k+1\" / \"#templates of length k\"\n",
    "            where #templates of length 0\" = n*(n - 1) / 2, by definition\n",
    "    Note:\n",
    "        The parameter 'sample_length' is equal to m + 1 in Ref[1].\n",
    "    References:\n",
    "        [1] http://en.wikipedia.org/wiki/Sample_Entropy\n",
    "        [2] http://physionet.incor.usp.br/physiotools/sampen/\n",
    "        [3] Madalena Costa, Ary Goldberger, CK Peng. Multiscale entropy analysis\n",
    "            of biological signals\n",
    "    \"\"\"\n",
    "    #The code below follows the sample length convention of Ref [1] so:\n",
    "    M = sample_length - 1;\n",
    "\n",
    "    time_series = np.array(time_series)\n",
    "    if tolerance is None:\n",
    "        tolerance = 0.2*np.std(time_series)\n",
    "\n",
    "    n = len(time_series)\n",
    "\n",
    "    #Ntemp is a vector that holds the number of matches. N[k] holds matches templates of length k\n",
    "    Ntemp = np.zeros(M + 2)\n",
    "    #Templates of length 0 matches by definition:\n",
    "    Ntemp[0] = n*(n - 1) / 2\n",
    "\n",
    "\n",
    "    for i in range(n - M - 1):\n",
    "        template = time_series[i:(i+M+1)];#We have 'M+1' elements in the template\n",
    "        rem_time_series = time_series[i+1:]\n",
    "\n",
    "        searchlist = np.nonzero(np.abs(rem_time_series - template[0]) < tolerance)[0]\n",
    "\n",
    "        go = len(searchlist) > 0;\n",
    "\n",
    "        length = 1;\n",
    "\n",
    "        Ntemp[length] += len(searchlist)\n",
    "\n",
    "        while go:\n",
    "            length += 1\n",
    "            nextindxlist = searchlist + 1;\n",
    "            nextindxlist = nextindxlist[nextindxlist < n - 1 - i]#Remove candidates too close to the end\n",
    "            nextcandidates = rem_time_series[nextindxlist]\n",
    "            hitlist = np.abs(nextcandidates - template[length-1]) < tolerance\n",
    "            searchlist = nextindxlist[hitlist]\n",
    "\n",
    "            Ntemp[length] += np.sum(hitlist)\n",
    "\n",
    "            go = any(hitlist) and length < M + 1\n",
    "\n",
    "\n",
    "    sampen =  - np.log(Ntemp[1:] / Ntemp[:-1])\n",
    "    return sampen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def SampEn(U, m, r):\n",
    "\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "\n",
    "        result = max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _phi(m):\n",
    "\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "\n",
    "        C = 1.*np.array([len([1 for j in range(len(x)) if i != j and _maxdist(x[i], x[j]) <= r]) for i in range(len(x))])\n",
    "        print (C)\n",
    "        return sum(C)\n",
    "\n",
    "\n",
    "    N = len(U)\n",
    "\n",
    "    \n",
    "\n",
    "    return -np.log(_phi(m+1) / _phi(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-dc3ea547e6ad>:1: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  eeg= mne.io.read_raw_eeglab('a.set')#, preload=True\n",
      "<ipython-input-6-dc3ea547e6ad>:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg= mne.io.read_raw_eeglab('a.set')#, preload=True\n"
     ]
    }
   ],
   "source": [
    "eeg= mne.io.read_raw_eeglab('a.set')#, preload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19987994 0.06822297]\n"
     ]
    }
   ],
   "source": [
    "sample_en= sample_entropy(eeg.get_data()[10], 2, 0.2*np.std(eeg.get_data()[2]))\n",
    "print (sample_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
